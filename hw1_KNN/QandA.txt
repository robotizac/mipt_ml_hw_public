Почему мы видим такую зависимость?

Потому что с изменением К меняются границы измерений для данных из тестовой выборки.
Соответственно попадает разное количество объектов разных классов из тренировочной выборки,
до которых проводится измерение расстояния. Это дает разные результаты классификации
для одних и тех же объектов и, как следствие, разные accuracy этих результатов.

Как ошибки связаны с расстоянием до других объектов класса?

Если есть объекты других классов, то чем дальше объект от других объектов своего класса,
тем больше вероятность того, что он будет ближе к объектам другого класса и тогда ошибка возрастает.
Ну и vice versa, само собой.

Какая реальная зависимость точности от гиперпараметра `k_neighbours`? Проведите анализ -- почему она такая?

Если брать `k_neighbours` слишком большим, то будут учитываться объекты которые находятся далеко.
А это уже противоречит самой идее KNN - оценки по ближайшим соседям. Таким образом гиперпараметр `k_neighbours`
надо подбирать оптимальный (например кросс валидацией).

Почему реализация "из коробки" отличается от нашей реализации? Подсказка: посмотрите в
[документацию](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier
.html?highlight=kneighbors#sklearn.neighbors.KNeighborsClassifier.kneighbors).

Реализация отличается большим выбором параметров и вариантами настройки классификатора.
Вопрос больше в том, почему результаты на одних и тех же К иногда отличаются.
Если честно, то сначала я думал что ничем не должны отличаться так как мы указываем ту же метрику и
не указываем, чтобы учитывались веса и алгоритм указываем брют форс
(KNeighborsClassifier(k, metric='euclidean', algorithm='brute')) 
Но потом на странице по ссылке нашел вот такое предупреждение 
"Warning Regarding the Nearest Neighbors algorithms, if it is found that two neighbors, neighbor k+1 and k, have identical distances but different labels, the results will depend on the ordering of the training data."
Думаю этим и объясняется разница при прочих равных.